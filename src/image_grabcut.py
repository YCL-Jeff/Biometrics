import cv2
import numpy as np
import mediapipe as mp
import os

# åˆå§‹åŒ– MediaPipe Pose
mp_pose = mp.solutions.pose
pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5)

def filter_green_background(image):
    """éæ¿¾ç¶ å¹•èƒŒæ™¯ï¼Œè¿”å›èƒŒæ™¯é®ç½©ï¼ˆç¶ å¹•å€åŸŸç‚º 0ï¼Œå…¶ä»–ç‚º 255ï¼‰"""
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    lower_green = np.array([40, 70, 70])
    upper_green = np.array([80, 200, 200])
    green_mask = cv2.inRange(hsv, lower_green, upper_green)
    background_mask = cv2.bitwise_not(green_mask)
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (25, 25))
    background_mask = cv2.morphologyEx(background_mask, cv2.MORPH_OPEN, kernel)
    return background_mask

def detect_pose_and_grabcut(image_path, output_path, scale_factor=0.5):
    """ä½¿ç”¨ MediaPipe åµæ¸¬é—œç¯€ + GrabCut æå–äººé«”è¼ªå»“ï¼Œè™•ç†ç¶ å¹•èƒŒæ™¯å’Œåœ°æ¿å•é¡Œ"""
    # è®€å–åœ–åƒ
    image = cv2.imread(image_path)
    if image is None:
        print(f"âŒ ç„¡æ³•è®€å–åœ–ç‰‡: {image_path}")
        return None

    h, w, _ = image.shape

    # ç¸®æ”¾åœ–ç‰‡ä»¥åŠ é€Ÿæª¢æ¸¬
    scaled_h, scaled_w = int(h * scale_factor), int(w * scale_factor)
    scaled_image = cv2.resize(image, (scaled_w, scaled_h), interpolation=cv2.INTER_LINEAR)
    scaled_rgb = cv2.cvtColor(scaled_image, cv2.COLOR_BGR2RGB)

    # MediaPipe å§¿å‹¢æª¢æ¸¬ï¼ˆåœ¨ç¸®æ”¾åœ–ç‰‡ä¸Šï¼‰
    results = pose.process(scaled_rgb)
    if not results.pose_landmarks:
        print(f"âš ï¸ MediaPipe æœªåµæ¸¬åˆ°äººé«”å§¿å‹¢: {image_path}")
        return None

    # å°‡é—œéµé»åº§æ¨™æ˜ å°„å›åŸå§‹å°ºå¯¸
    keypoints = [(int(lm.x * w), int(lm.y * h)) for lm in results.pose_landmarks.landmark]

    # éæ¿¾ç¶ å¹•èƒŒæ™¯
    green_mask = filter_green_background(image)

    # æ”¹é€²åˆå§‹çŸ©å½¢ï¼Œæ¸›å°‘åœ°æ¿åŒ…å«
    head_y = min(keypoints[7][1], keypoints[8][1], keypoints[11][1], keypoints[12][1]) - 150  # æ¸›å°‘é ­é ‚ padding
    ankle_y = max(keypoints[27][1], keypoints[28][1]) + 20  # æ¸›å°‘è…³è¸ paddingï¼Œé¿å…åœ°æ¿
    body_x_min = min(keypoints[11][0], keypoints[12][0], keypoints[15][0], keypoints[16][0], keypoints[23][0], keypoints[24][0]) - 120
    body_x_max = max(keypoints[11][0], keypoints[12][0], keypoints[15][0], keypoints[16][0], keypoints[23][0], keypoints[24][0]) + 120

    # é˜²æ­¢åº§æ¨™è¶…å‡ºé‚Šç•Œ
    rect = (
        max(0, body_x_min),
        max(0, head_y),
        min(w, body_x_max) - max(0, body_x_min),
        min(h, ankle_y) - max(0, head_y)
    )

    # åˆå§‹åŒ– GrabCut é®ç½©
    mask = np.zeros(image.shape[:2], np.uint8)
    bgdModel = np.zeros((1, 65), np.float64)
    fgdModel = np.zeros((1, 65), np.float64)

    # å°‡ç¶ å¹•å€åŸŸæ¨™è¨˜ç‚ºç¢ºå®šèƒŒæ™¯
    mask[green_mask == 0] = cv2.GC_BGD

    # åŸ·è¡Œ GrabCut
    cv2.grabCut(image, mask, rect, bgdModel, fgdModel, 10, cv2.GC_INIT_WITH_RECT)

    # å‰µå»ºå‰æ™¯é®ç½©
    mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')

    # æ‰¾æœ€å¤§è¼ªå»“ä¸¦éæ¿¾
    contours, _ = cv2.findContours(mask2, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if not contours:
        print(f"âš ï¸ æ‰¾ä¸åˆ°è¼ªå»“: {image_path}")
        return None

    # éæ¿¾è¼ªå»“ï¼ˆæ ¹æ“šé¢ç©å’Œé«˜åº¦ç¯„åœï¼‰
    min_area = h * w * 0.02  # è‡³å°‘ 2% çš„åœ–åƒé¢ç©
    filtered_contours = []
    for cnt in contours:
        area = cv2.contourArea(cnt)
        if area < min_area:
            continue
        x, y, w_cnt, h_cnt = cv2.boundingRect(cnt)
        # æª¢æŸ¥è¼ªå»“é«˜åº¦æ˜¯å¦åœ¨é ­é ‚åˆ°è…³è¸ç¯„åœå…§
        if y < head_y or (y + h_cnt) > ankle_y + 50:  # å…è¨±å°ç¯„åœè¶…å‡º
            continue
        # æª¢æŸ¥é•·å¯¬æ¯”ï¼ˆå‡è¨­äººé«”é•·å¯¬æ¯”ç¯„åœï¼‰
        aspect_ratio = w_cnt / h_cnt if h_cnt > 0 else 0
        if 0.02 < aspect_ratio < 4.0:  # æ”¾å¯¬ç¯„åœï¼Œé©æ‡‰å´é¢å§¿å‹¢
            filtered_contours.append(cnt)

    if not filtered_contours:
        print(f"âš ï¸ æ‰¾ä¸åˆ°ç¬¦åˆæ¢ä»¶çš„è¼ªå»“: {image_path}")
        return None

    largest_contour = max(filtered_contours, key=cv2.contourArea)

    # å‰µå»ºä¹¾æ·¨çš„é®ç½©
    clean_mask = np.zeros_like(mask2)
    cv2.drawContours(clean_mask, [largest_contour], -1, 255, thickness=cv2.FILLED)

    # å½¢æ…‹å­¸æ“ä½œï¼ˆå»é™¤åœ°æ¿å™ªé»ï¼‰
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (20, 20))
    final_mask = cv2.morphologyEx(clean_mask, cv2.MORPH_CLOSE, kernel)
    final_mask = cv2.morphologyEx(final_mask, cv2.MORPH_OPEN, kernel)

    # æ‡‰ç”¨é®ç½©
    result = image * (final_mask[:, :, np.newaxis] // 255)

    # ç¹ªè£½è¼ªå»“å’Œé‚Šç•Œæ¡†ï¼ˆå¯è¦–åŒ–ç”¨ï¼‰
    result_with_contour = image.copy()
    cv2.drawContours(result_with_contour, [largest_contour], -1, (0, 0, 255), 2)
    x, y, w_box, h_box = cv2.boundingRect(largest_contour)
    cv2.rectangle(result_with_contour, (x, y), (x + w_box, y + h_box), (255, 0, 0), 2)

    # ä¿å­˜çµæœ
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    success = cv2.imwrite(output_path, result)
    if success:
        print(f"âœ… GrabCut è™•ç†å¾Œå½±åƒæˆåŠŸå„²å­˜è‡³: {output_path}")
    else:
        print(f"âŒ GrabCut å½±åƒå„²å­˜å¤±æ•—: {output_path}")

    # ä¿å­˜å¸¶è¼ªå»“çš„çµæœ
    contour_output_path = output_path.replace(".jpg", "_contour.jpg")
    cv2.imwrite(contour_output_path, result_with_contour)
    print(f"âœ… è¼ªå»“çµæœå„²å­˜è‡³: {contour_output_path}")

    # ä¿å­˜æœ€çµ‚é®ç½©
    mask_output_path = output_path.replace(".jpg", "_mask.jpg")
    cv2.imwrite(mask_output_path, final_mask)
    print(f"âœ… é®ç½©å„²å­˜è‡³: {mask_output_path}")

    return result

def batch_process_images(input_dir, output_dir, scale_factor=0.5):
    supported_formats = ('.jpg', '.jpeg', '.png', '.bmp')
    for filename in os.listdir(input_dir):
        if filename.lower().endswith(supported_formats):
            input_path = os.path.join(input_dir, filename)
            output_path = os.path.join(output_dir, f"grabcut_{filename}")
            print(f"ğŸš€ è™•ç†åœ–ç‰‡: {filename}")
            detect_pose_and_grabcut(input_path, output_path, scale_factor)

if __name__ == "__main__":
    input_directory = r"C:\Biometrics\data\training"
    output_directory = r"C:\Biometrics\data\results"
    batch_process_images(input_directory, output_directory, scale_factor=0.5)
    print("âœ… æ‰¹é‡è™•ç†å®Œæˆ")